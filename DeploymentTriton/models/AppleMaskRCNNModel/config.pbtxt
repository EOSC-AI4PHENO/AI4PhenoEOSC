name: "AppleMaskRCNNModel"
platform: "tensorflow_savedmodel"
max_batch_size: 0
input [
  {
    name: "input_image"
    data_type: TYPE_FP32
    format: FORMAT_NONE
    dims: [-1,-1, -1, 3]  # W, H, C to wymiary obrazu
  },
  {
    name: "input_anchors"
    data_type: TYPE_FP32
    format: FORMAT_NONE
    dims: [-1,-1,4]  # A to wymiar dla anchor√≥w
  },
  {
    name: "input_image_meta"
    data_type: TYPE_FP32
    format: FORMAT_NONE
    dims: [-1,14]  # M to wymiar dla metadanych obrazu
  }
]
output [
  {
	name: "ROI"
	data_type: TYPE_FP32
	dims: [1,1000,4]
  },
  {
	name: "mrcnn_bbox"
	data_type: TYPE_FP32
	dims: [1,1000,2,4]
  },
  {
	name: "mrcnn_class"
	data_type: TYPE_FP32
	dims: [1,1000,2]
  },
  {
	name: "mrcnn_detection"
	data_type: TYPE_FP32
	dims: [1,100,6]
  },
  {
	name: "mrcnn_mask"
	data_type: TYPE_FP32
	dims: [10]
  },
  {
	name: "rpn_bbox"
	data_type: TYPE_FP32
	dims: [10]
  },
  {
	name: "rpn_class"
	data_type: TYPE_FP32
	dims: [10]
  }
]